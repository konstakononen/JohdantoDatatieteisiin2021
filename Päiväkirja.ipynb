{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Johdanto datatieteisiin 2021\n",
    "\n",
    "Konsta Könönen \n",
    "H267400\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aloitan oppimispäiväkirjoittamisen kunnolla 17.4. kiireiden vuoksi, joten kurssi tulee tehtyä kohtuullisen nopealla aikataululla. Olen kuitenkin odottanut kurssin suorittamista ja varsin innoissani tästä sisällöstä, joten uskon oppivani paljon. \n",
    "Tavoitteeni arvosanalle on 4-5, joten sen tasoisen harjoitustyön pyrin tekemään. Oppimispäiväkirjaan tulee panostettua, kun opiskelee aiheesta ja aiheen vierestä. :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luentoviikko 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Johdanto aihepiiriin ja suorittaminen\n",
    "\n",
    "Olin luennolla ja demotilaisuudessa mukana reaaliajassa. Luennolla tuli paljon tuttua asiaa, mutta myös vähän uusia näkökulmia. Neljä tietojohtamista opiskelleena CRISP-DM, datatieteen metrokartat ja Venn-diagrammit olivat hyvin tuttuja. Paras anti alkoi tulla oikeastaan teknologian näkökulmasta, sillä ilmeisesti \"datajutskien\" koodaaminen on tietyllä tapaa hyvin erilaista kuin perusohjelmointi. Minulla on ollut ohjelmointi sivuaineena ja töissä olen tehnyt BI-työkaluilla paljon asioita. Jukan tiivistys BI-työkaluista oli mielestäni erinomainen: kaupallistettua datan käsittelyä. Tähän on helppo yhtyä ja datan käsittely on onnistuttu tuotteistamaan nykyisin myös dataputkien ja tietovarastojen osalta kohtuullisen helppokäyttöisiksi ohjelmiksi, joita voi rakennella graafisella käyttöliittymällä. Visualisointi Power BI:llä tai Qlik Sensellä on erityisen helppoa, jopa helpompaa kuin excelissä. \n",
    "\n",
    "Luennon tärkein oppi tulikin datatieteen kiteytyksestä ja siitä, miten se eroaa liiketoimintatiedonhallinnasta. Liiketoimintatiedonhallinnassa data kerätään liiketoiminnan tietojärjestelmistä ja analytiikkaa ohjaa vahvasti päätöksenteon tietotarpeet. Datatieteessä tietotarpeet eivät ole lähtökohta vaan data. Datasta pyritään löytämään sellaisia asioita, joita ei edes tiedetä löytyvän. Molemmissa voidaan käyttää samoja teknologioita, mutta lähtökohdat tekemiseen ovat erilaiset. \n",
    "\n",
    "Anaconda ja Jupyter Notebook ovat itselle uusia tuttavuuksia. Notebook vaikuttaa loogiselta ja siinä on tietyllä tapaa paljon samoja elementtejä, kuin Power Queryn rakentelussa. Ensimmäinen luentoviikko oli varsin pehmeä startti kurssille. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 oivallusta \n",
    "- Datatieteen lähtökohtana on data, josta voi löytyä jotain uutta ja kiinnostavaa tai sitten ei löydy\n",
    "- Kun koodataan data-analytiikka itse, tiedetään paremmin mitä tapahtuu verrattuna BI-työkaluihin\n",
    "- Jupyteria on kehuttu todella paljon monissa lähteissä, mutta pari vuotta sitten en olisi osannut/ymmärtänyt mitään. Nyt Jupyter vaikuttaa todella helpolta. Ei pidä olettaa, että kaikki osaisivat nopeasti käyttää sitä tai että se olisi kaikille helppoa\n",
    "- Pandas on verrattavissa perustoimininnoiltaan excelin pyörittelyyn tai taulujen jalostamiseen osa kerrallaan BI-työkalulla\n",
    "- Oivalsin, että en edes tiedä miten vähän tiedän datatieteestä, sen mahdollisuuksista ja soveltamisesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Esimerkki  Sarake        CSV\n",
      "0           1      A   Toimiiko\n",
      "1           2      B      tämä \n",
      "2           3      C  tiedoston\n",
      "3           4      D     avaus \n",
      "4           5      E     oikein\n",
      "Indeksi       int64\n",
      "Kategoria    object\n",
      "Tietue       object\n",
      "dtype: object\n",
      "\n",
      "Uudet tietotyypit\n",
      "Indeksi         int64\n",
      "Kategoria    category\n",
      "Tietue         object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indeksi</th>\n",
       "      <th>Kategoria</th>\n",
       "      <th>Tietue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>Toimiiko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>tämä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>tiedoston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>avaus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td>oikein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Indeksi Kategoria     Tietue\n",
       "0        1         A   Toimiiko\n",
       "1        2         B      tämä \n",
       "2        3         C  tiedoston\n",
       "3        4         D     avaus \n",
       "4        5         E     oikein"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Koodiesimerkki: tiedoston avaaminen suoraan pandaksen dataframeen\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"Oppimispaivakirja_Esimerkki.csv\", delimiter=';')\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.rename(columns= {'Esimerkki ': 'Indeksi', 'Sarake': 'Kategoria', 'CSV': 'Tietue' }, inplace=True)\n",
    "\n",
    "print(df.dtypes)\n",
    "df['Kategoria'] = df['Kategoria'].astype('category')\n",
    "\n",
    "print(\"\\nUudet tietotyypit\")\n",
    "print(df.dtypes)\n",
    "\n",
    "df.set_index('Indeksi')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tärkeimmät kehityskohdat\n",
    "\n",
    "Kurssilla aletaan heti puhua harjoitustyön tekemisestä ja tarjotaan laaja valikoima työkaluja (ehkä liiankin laaja). Vaikka kurssi suoritetaan lyhyessä ajassa ja asiaa on paljon, niin mielestäni ensimmäinen viikko / kaksi voitaisiin käyttää parin harjoitustehtävän tekemiseen. Kovin henkilökohtainen mielipide ja ennen oli ilmeisesti alustus kurssi ennen tätä. Itse opin paremmin tekemällä ja siksi olisi ollut mukava aloittaa hitaasti tärkeimmillä perusjutuilla, jonka jälkeen olisi vapautettu etenemään omaa tahtia. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luentoviikko 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datan kerääminen ja jalostaminen\n",
    "\n",
    "Katsoin molemmat tilaisuudet tallenteelta. Äärimmäisen mielenkiintoinen luento ja tuli paljon sellaisia ohjeita/työkaluja siihen, mitä joskus on haaveillut itse puuhailevansa. BI-työkaluilla analytiikkaa tehdessä datan pitää olla hyvin jäsenneltyä eli se ladataan tiedostosta tai sitten jonkun rajapinnan kautta tietokannasta/palvelusta. Jupyter, python ja pythonin kirjastot mahdollistavat itse datan keräämisen mitä ihmeellisimmistä paikoista ja internetin syövereistä. Päätin samantien, että harjoitustyössä haluan itse kerätä datan joltain verkkosivulta. BeautifulSoup käytiin osittain luennolla läpi ja klinikalla keskityttiin scrapyyn. BeautifulSoupista oli verkossa hyviä tutoriaaleja, joiden avulla tein ensimmäiset kokeilut. Olisin halunnut tehdä harjoitustyön myytävien asuntojen analysoinnista, mutta datan keräämisessä tuli tiettyjä haasteita Oikotien palvelusta. Yksittäisten asuntojen tietojen haku onnistui hyvin, mutta etusivulta kohteiden listausta en onnistunut tekemään, koska kohteet oli piilotettu koodipalikan sisään sivuston rakenteessa. Harjoittelin Oikotien sivustolla, mutta harjoitustyössä tein raapimisen Liigan sivuilta. \n",
    "\n",
    "Samalla, kun yritin työstää datasettiä Oikotien palvelusta, törmäsin myös eettisiin haasteisiin. Huomasin, että Oikotie oli kieltänyt sivujen raavinnan tietosuojassaan. Tutkin hieman asiaa ja raavinnasta oli oikeusjuttuja, joissa raavinta oli todettu lailliseksi. Mietin kuitenkin, että kuka datan oikein omistaa; Oikotie vai asunnon myyntiin laittanut välittäjä vai asunnon omistaja? Jos tiedot on julkisesti jaettu, niin saako niitä sitten tallentaa käsin kirjoittamalla? Mikä ero siinä on automaattiseen raavintaan? Nämä ovat hankalia asioita eikä verkosta tuntunut löytyvän konsensusta mielipiteestä. \n",
    "\n",
    "Datatieteen työprosessi oli minulle uusi käsite ja kuvaus, joka on oikein hyödyllinen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 oivallusta \n",
    "- Crawling/scraping mahdollistaa sellaisen datan keräämisen, jota ei muuten saisi käyttöönsä. \n",
    "- Onko ruudunraavinta datan varastamista? Eettisesti haastava aihe. \n",
    "- Monet yritykset eivät edes tiedä millaisia hyötyjä voisivat saavuttaa raavinnan avulla: https://greenice.net/4-ways-business-can-benefit-web-scraping/\n",
    "- Taitava koodari voisi rakentaa työkalun, joka kerää tiedot kaikista vedonlyöntipalveluista ja algoritmien avulla tunnistaa arbitraasit vedonlyöntikohteiden kertoimissa. Näitä arbitraaseja löytyy, mutta niiden etsiminen on vaivalloista. \n",
    "- \"Datatieteilijä keskittyy ymmärtämään datan tuottamaa arvoa\" --> Jotta ymmärtää datan tuottaman arvon, pitää ymmärtää liiketoimintaa. Kumpi datatieteilijälle tällöin on tärkeämpää, teknologinen/matemaattinen osaaminen vai se, että osaa tunnistaa nämä arvoa tuottavat asiat eli liiketoimintaosaaminen? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 m² Itkonniemenkatu 4a B, 70500 Kuopio Kerrostalo Kaksio myynnissä - Oikotie 16149442\n",
      "Sijainti: Itkonniemenkatu 4a B, 70500 Kuopio\n",
      "Kaupunginosa: Itkonniemi\n",
      "Kohdenumero: 504627\n",
      "Kerros: 2 / 4\n",
      "Asuinpinta-ala: 54 m²\n",
      "Tontin pinta-ala: 3 148 m²\n",
      "Kokonaispinta-ala: 54 m²\n",
      "Huoneiston kokoonpano: 2h,kt,s\n",
      "Huoneita: 2\n",
      "Lisätietoa vapautumisesta: Sopimuksen mukaan\n",
      "Keittiön varusteet: Jääkaappipakastin, erillisuuni, liesitaso keraaminen, liesituuletin, astianpesukone, kaapistot valkoiset, kiinteät valaisimet. työtasot massiivitammi\n",
      "Parveke: Kyllä\n",
      "Kylpyhuoneen varusteet: Sauna, sähkökiuas, kylpyhuone, suihku, suihkuseinä, peilit, allaskaappi, pesukoneliitäntä, lattialämmitys, kiinteät valaisimet.\n",
      "Säilytystilat: Kellari, jäähdytetty kellari\n",
      "Näkymät: Itä\n",
      "Tulevat remontit: Suunnitellut: IV-kanavien puhdistus ja säätö, vesikaton kuntokartoitus, 10-vuotistakuutarkastus\n",
      "Tehdyt remontit: 2019 Pihakannen vuotojen korjailuja,\n",
      "2015 Asennettu Bauerin vedenkäsittelylaitteisto käyttöveteen\n",
      "Asunnossa sauna: Kyllä\n",
      "Asumistyyppi: Omistus\n",
      "Palvelut: Palvelut: Sataman kaupat. Koulut: Keskustan koulut. Päiväkoti: Vastapäisessä talossa.\n",
      "Kohde on: Osakehuoneisto\n",
      "Ensiesittelyssä: Ei\n",
      "Postitoimipaikka: KUOPIO\n",
      "Linkit: Tilaa sähköinen esite\n",
      "Velaton hinta: 183 000 €\n",
      "Myyntihinta: 183 000 €\n",
      "Neliöhinta: 3 388,89 € / m2\n",
      "Lunastuspykälä: Lunastusoikeus on osakkailla.\n",
      "Rahoitusvastike: 0 € / kk\n",
      "Hoitovastike: 178,20 € / kk\n",
      "Yhtiövastike: 178,20 € / kk\n",
      "Vesimaksun lisätiedot: Mittarin mukaan\n",
      "Muut kustannukset: Vesimaksuennakko 13 €/hlö/kk. Asunnon yhteydessä myydään autohallipaikka omalla osakesarjalla hintaan 10 000 €. Autohallivastike 13,20 €/kk.\n",
      "Lunastettavan vuokratontin vastike : 0 € / kk\n",
      "Vuokratontin lunastusosuus: 0 €\n",
      "Uudiskohde: Ei\n",
      "Taloyhtiön nimi: Asunto Oy Kuopion Konduktööri\n",
      "Rakennuksen tyyppi: Kerrostalo\n",
      "Rakennusvuosi: 2011\n",
      "Huoneistojen lukumäärä: 50\n",
      "Liiketilojen pinta-ala: 0 m²\n",
      "Liikehuoneistojen lukumäärä: 0\n",
      "Rakennuksen käyttöönottovuosi: 2011\n",
      "Kerroksia: 4\n",
      "Hissi: Kyllä\n",
      "Taloyhtiössä on sauna: Ei\n",
      "Rakennusmateriaali: Betoni\n",
      "Kattomateriaali: Bitumihuopa\n",
      "Kattotyyppi: Tasa\n",
      "Energialuokka: B2007 Laatija Risto Lammentausta 31.5.2013\n",
      "Energiatodistus: Kyllä\n",
      "Tontin koko: 3 148 m²\n",
      "Tontin omistus: Oma\n",
      "Kiinteistönhoito: Huoltoyhtiö\n",
      "Isännöinti: Kuopion Talokeskus Oy/Päivi Koponen, puh. 017 288 2500\n",
      "Kaavoitustiedot: Kuopion kaupunki\n",
      "Kaavatilanne: Asemakaava.\n",
      "Liikenneyhteydet: Bussit, pysäkki talon kohdalla, 3 x tunnissa\n",
      "Lämmitys: Kaukolämpö\n",
      "Kunnan numero: 297\n",
      "Lisätietoja talosta: Siirry talosivulle\n",
      "Yhteiset tilat: Kuivaushuone, urheiluvälinevarasto, väestösuoja, mahdollisuus autopaikkaan\n",
      "Pintamateriaalit: Sauna: paneloitu. Kylpyhuone: laatoitettu. Lattiat: tammiparketti. Seinät: Maali / Tapetti.\n"
     ]
    }
   ],
   "source": [
    "# Koodiesimerkki: raapija, joka kerää Oikotien palvelusta myynnissä olevan asunnon tiedot\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "apartment = {}\n",
    "\n",
    "url = \"https://asunnot.oikotie.fi/myytavat-asunnot/kuopio/16149442\"\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "title = soup.title\n",
    "print(title.string)\n",
    "\n",
    "for all_apartmentDetails in soup.find_all('div', {'class': 'info-table__row'}):\n",
    "    for item in all_apartmentDetails.find_all('dt'):\n",
    "        attr = item.text\n",
    "    for value in all_apartmentDetails.find_all('dd'):\n",
    "        test = value.text\n",
    "    apartment[attr] = test\n",
    "\n",
    "for key, value in apartment.items():\n",
    "    print(key + ': '+ value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tärkeimmät kehityskohdat\n",
    "\n",
    "Luentoviikon aihetta tulisi lähestyä mielestäni enemmän hyöty/etiikka näkökulmista, sillä ne tekevät aiheesta tärkeän ja erittäin mielenkiintoisen. Tekniseen opetukseen hyvä siirtyä sen jälkeen. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luentoviikko 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koneoppimisen periaatteet \n",
    "\n",
    "Katsoin tilaisuudet tallenteelta. Koneoppimisen luentoviikko oli mukavaa syventymistä aiheeseen, jota on tullut ihmeteltyä monesta eri näkökulmasta, mutta loppupeleissä vähän teknisistä näkökulmista. Työelämässä olen törmännyt siihen, että koneoppimista saatetaan hyödyntää esimerkiksi datan laadun parantamiseen. Spike detection on algoritmi, jonka avulla voidaan tunnistaa piikkejä/poikkeamia datassa. Kyseinen algoritmi tarvitsee paljon dataa toimiakseen ja silloin poikkeamat jäävät kiinni. Tunnistan tässä tietyllä tapaa ristiriidan sillä datan laatuongelmia ei voida, kokonaan ratkaista koneoppimisella. Samaan aikaan koneoppimisen laatu on riippuvainen datan laadusta.  Toisaalta ristiriitaa ei todellisuudessa ole, koska datan laatuongelmia ei tulisi ratkaista koneoppimisella. Olen myös pähkäillyt, että datan laatua saatetaan parantaa jalostamalla dataa, mutta syntyykö silloin informaatiota eikä laadukasta dataa.. En kuitenkaan avaa näitä tiedon tasoihin liittyviä mietteitä enempää..\n",
    "\n",
    "Luennolla tuli datan laadun lisäksi maininta siitä, että ei ole olemassa raakadataa vaan kaikki data on jollain tapaa käsiteltyä ja järjestyksessä. Tästä en ole täysin samaa mieltä, tai riippuu toki mitä tarkoitetaan raakadatan käsitteellä. Joillekin raakadata on tietokannasta ladattua dataa, jota pitää alkaa jalostaa ja jollekin se voi olla itse kerättyä dataa, jolle ei ole tehty mitään. Ymmärrän pointin siitä, että data kertoo aina jotain, olipa se raakaa tai jalostettua, mutta raaka-käsite tulee mielestäni siitä ettei datalle ole tehty mitään. Esimerkiksi koneiden/mittareiden tuottama prosessidata on hyvä esimerkki raakadatasta.\n",
    "\n",
    "Ohjatussa koneoppimisessa käytetään lähes aina opetusaineistoa, jos ei käytetä opetusaineistoa, niin kyseessä on jatkuvan oppimisen malli. Opetusaineiston oikeellisuus on siten kaikki kaikessa, koska muuten tehdystä mallista ei ole mitään apua. Jos opetusaineisto on vääristynyttä, niin malli saattaa aiheuttaa jopa vaaratilanteita väärillä tuloksillaan. Esimerkiksi lääkärit kasvavissa määrin alkavat käyttää koneoppimismallien tuottamia tuloksia omissa diagnooseissaan. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 oivallusta \n",
    "- Ohjatun koneoppimisen tarkoitus on \n",
    "- Jotta koneoppiminen on tehokasta ja tarkkaa, dataa tarvitaan erittäin paljon \n",
    "- Koneoppimisen algoritmejä on hyvin yksinkertaisia, mutta myös äärimmäisen hankalia \n",
    "- Koneoppimismalleihin löytyy paljon kirjastoja pythonille, mikä tekee koneoppimisen hyödyntämisestä erittäin helppoa verrattuna siihen, että yrittää BI-työkaluilla rakennella itse regressiota\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koodiesimerkki: esimerkki on harjoitustyöstä ja samalla algoritmilla tehtiin demosessiossa lineaarista regressiota. \n",
    "# Esimerkki on yksinkertaisuudessaan kaunis. \n",
    "# Tämä on äärimmäisen hyvä osoitus siitä, miksi analytiikan tekeminen itse koodaamalla on kannattavaa \n",
    "\n",
    "# Sama toteutettuna PowerBI:ssä vaatii paljon datan muokkailuja datasettiin / uusia sarakkeita, joista sitten tehdään mittareita\n",
    "# Mittareiden avulla voidaan graafissa esittää lineaarisen regression tulokset --> nyt vaatii pari riviä koodia\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "# lineaarinen regressio \n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "x = ML_df['P'].values[:,np.newaxis]\n",
    "y = ML_df['M']\n",
    "\n",
    "classifier = lr.fit(x,y)\n",
    "\n",
    "plt.scatter(x,y, color='Green')\n",
    "plt.plot(x, classifier.predict(x), color='Yellow')\n",
    "plt.xlabel('Pisteet')\n",
    "plt.ylabel('Maalit')\n",
    "plt.title('Pisteiden määrän vaikutus maaleihin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luentoviikko 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harjoitustyöhön tutustuminen \n",
    "\n",
    "Katsoin tilaisuudet tallenteelta. Luennolla esiteltiin erilaisia prosesseja, joiden pohjalta voi työstää harjoitustyötä eteenpäin. Mielenkiintoisin nosto oli Houston Analyticsin Agile CRISP-DM, jossa CRISP-DM prosessi oli jaoteltu kahden joukon vastuualueisiin. Tässä korostuu mielestäni tietojohtamisen tärkein olemus siitä, kuinka rakennetaan business caseja tai palvellaan analytiikkatuotteen asiakasta (sisäinen/ulkoinen). Tämä prosessimalli nyt kuitenkin sotii ensimmäisen luennon mainintaa vastaan, jossa sanottiin, että datatieteen näkökulma lähtee itse datasta. Tästä voidaan palata siihen, kuinka käsitteet alalla menevät sekaisin ja hieman vaihtelevat aiheesta riippuen. \n",
    "\n",
    "Luennolla esitellyn streamlit -työkalun voisin rakentaa interaktiivisen dashboardin tai ylipäänsä hostattavan analytiikkatuotteen, mutta en saanut asennettua siihen tarpeellisia kirjastoja anacondan avulla. Toivottavasti se onnistuisi harjoitustyöhön. \n",
    "\n",
    "Harjoitustyön prosessia miettiessä sain idean, että voisinkohan palastella datan kerääminen, jalostuksen ja esittämisen useampaan notebookiin eikä vain yhteen pitkään muistioon. Tämähän onnistuu ja päätin toteuttaa sen yksinkertaisesti tallentamalla eri vaiheista csv-tiedostoja, joista muodostuu lopullinen tietomalli analytiikan rakenteluun. Alla kuva teknisestä prosessista. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Oppimispaivakirja_MasterNotebook.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 oivallusta \n",
    "- Tietotarpeiden tunnistaminen on vaikeaa ja usein ajatellaan liian kapeakatseisesti. Tähän liittyy monesti ongelma tunnistaminen ja oikeiden kysymysten kysyminen, mutta ongelmat ovat myös sidoksissa toisiinsa, jolloin tietotarpeiden tunnistamisessa pitäisi tunnistaa laajemmat ongelmat. Jos tietotarpeiden määrittely menee liian ylätasolle, niin silloin ratkaisun rakentaminen on miltei mahdotonta, koska pitäisi vastata analytiikkaratkaisu, joka tarjoaa kaikille kaiken.  \n",
    "- Mahdollisuus canvas on oiva työkalu yrityksen analytiikkatiimille, kun se palvelee liiketoimintoja\n",
    "- Joka luennolla mukana ollut skicit-learn algorithm cheat-sheet näyttää ensimmäistä kertaa järkevälle :D. Yleensä ongelmaa ratkottaessa keskitytään yhteen osioon kerrallaan, mutta tuo auttaa käytännössä hahmottamaan sen tyyppisen tekniikan, jota tarvitsee ongelmanratkaisemiseen. \n",
    "- Harjoitustyön vaikein osio on datan siivoamisessa, kun data on hyvässä järjestyksessä, algoritmitmien pitäisi toimia moitteetta. Haasteet tuntuvat johtuvan aina väärän tyyppisestä tai rikkonaisesta datasta. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koodiesimerkki: liittyy lähinnä edellä esitettyihin kuviin\n",
    "# olennaisia ovat siis dataframen tallentaminen csv:ksi ja saman csv:n lataaminen sitten toisessa notebookissa\n",
    "import pandas as pd\n",
    "\n",
    "# Tallennetaan datasetti csv-tiedostoon (tarvittaessa vanhan korvaaminen)\n",
    "df.to_csv(r'C:\\Users\\35840\\Documents\\JohdantoDatatieteisiin2021\\JohdantoDatatieteisiin2021\\Harjoitustyö\\PlayersStats_by_Season.csv', index = False, header=True)\n",
    "print(\"Tallennettu PlayersStats_by_Season.csv \\n\")\n",
    "\n",
    "# Ladataan datasetit\n",
    "df_Players = pd.read_csv('PlayersStats_by_Season.csv')\n",
    "df_Plaer_Info = pd.read_csv('Player_Information.csv')\n",
    "df_Players_Salaries = pd.read_csv('PlayersSalaries_by_Season.csv')\n",
    "\n",
    "# Yhdistetään datasetit left joinilla\n",
    "dataset = df_Players.merge(df_Plaer_Info, on='pelaaja_id', how='left')\n",
    "\n",
    "#nämä koodirivit eivät osaa tehdä mitään, koska data on eri polun takana. Toimivat vain esimerkkinä. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tärkeimmät kehityskohdat\n",
    "\n",
    "Ei erityistä kehitysehdotusta tälle luentoviikolle. Järkevä ja hyvä kokonaisuus, aiheetkaan toki ei ollut kovin laajoja.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luentoviikko 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vierailuluento luonnollisen kielen analyysistä  \n",
    "\n",
    "Katsoin tilaisuudet tallenteelta. Vierailuluento oli hyvin vauhdikas ja oli haastavaa pysyä mukana, koska aihe oli itselle täysin uusi. NLP oli toki tuttu käsite, mutta mitään teknologisesti konkreettista siihen liittyen ei ole tullut opeteltua, joten tässä tuli oikein hyvä esimerkki käytännöstä. \n",
    "\n",
    "Luennolla sivuttiin sitä, miksi NLP on merkityksellistä, mutta perustelut jäi tietyllä tapaa vaillinaiseksi. Ajattelin vähän selvitellä, mitä kaikkea potentiaalia NLP:ssä on ja löysin hyvän artikkelin: https://towardsdatascience.com/why-nlp-is-important-and-itll-be-the-future-our-future-59d7b1600dda. Yksinkertaisesti se, että tekstidataa on niin valtavasti tarjolla, muttei sen käsittelyyn ole kunnollista työkalua korostaa NLP:n tärkeyttä. NLP:n avulla rakenteeton tekstidata rakenteellistetaan ja mahdollistetaan kaiken tekstidatan analysointi. Tästä avautuu sellaisia mahdollisuuksia tutkimukseen ja ihmisiin vaikuttamiseen, mitä ei ole ennen ollut. Uskon, että yksi NLP:n tärkeimmistä tarkoituksista tulee olla valeuutisten filtteröinnissä. Valheellinen viestintä tulee olemaan nykyisen maailman yksi vakavimmista ja vaikeimmista ongelmista. \n",
    "\n",
    "Luennolta tuli paljon hyödyllistä tietoa, mutta en käytä NLP:tä harjoitustyössä, joten koodiesimerkkiin etsin mielenkiintoisen esimerkin verkosta. Oivalluksista avattu vierailuluennon tärkeimpiä oppeja. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 oivallusta \n",
    "- Esikäsittelyn roolia vaikea ylikorostaa. Luentoviikosta jäi sellainen vaikutus, että esikäsittelyn rooli NLP:ssä on tärkeämpää kuin muualla, koska datalla ei ole kunnollista rakennetta. \n",
    "- Stopwords eli hukkasanat --> Tärkeä osa NLP:tä eikä ole staattinen lista vaan arvioitava käyttötapauksen mukaan\n",
    "- Dilemma kirjastojen ja itse tehdyn koodin välillä: miten tunnistaa raja milloin käyttää valmiita kirjastoja ja milloin koodata itse. Jotkut kirjastot tai funktiot voivat olla ns. blackboxeja eli ei ole kunnollista näkyvyyttä mitä tapahtuu. Myös oma ymmärrys kirjaston toiminnassa voi olla vaillinen, jolloin datatuotoksen luotettavuus kärsii. \n",
    "- Tällä hetkellä ihmiset kehittävät koneoppimismalleja ja MLOps pyrkii parantamaan tämän kehittämisen versionhallintaa / automatisointia. Kauanko kestää rakentaa tekoäly tms, joka osaa itse rakentaa vaihtoehtoisia koneoppimismalleja tekstimassan perusteella. Eli käyttäjä antaisi pelkän syötteen ja saisi vastauksena vaihtoehtoiset koneoppimismallit perusteluineen. En tiedä onko liian scifi-ajatus, mutta kehitys tuntuu olevan, niin nopeaa, että johonkin tällaiseen pyritään. Vierailuluennoitsijaa lainaten \"pidetään flow mielekkäänä\". Tässäkin tosin kohdataan aiemmin mainittu dilemma blackboxin ja itse koodatun osalta. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tärkeimmät kehityskohdat\n",
    "\n",
    "- Jälkikäteen tallenneelta katsottuna vaikutti siltä, että vieraililuennoitsijoilla liikaa härveleitä opetuksen ohessa, kyselyitä kolmessa eri portaalissa\n",
    "- colabin jakaminen oikein hieno ja kurssiopetuksessakin voitaisiin hyödyntää vastaavaa metodia :) Pääsee opetuksen yhteydessä ajamaan valmista rakennetta. Osittain toki toteutaa demoluennoilla\n",
    "- Vierailuluento yleisesti hyvä lisä kurssinantiin eikä siinä sen kummemmin kehitettävää, mukava seurata työelämän esimerkkejä.  Pitäkää mukana jatkossakin!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luentoviikko 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ohjaamaton koneoppiminen\n",
    "\n",
    "Katsoin tilaisuudet tallenteelta. Ohjaamaton oppiminen oli aiheena hyvin haastava, en ollut kuullut ennen ryvästämisestä tai aihemallinnuksesta, joten käytännön erottaminen teoreettisesta tuotti jo tietyllä tapaa vaikeuksia. Ohjaamattomuus käsitteessä tarkoittaa lähinnä, että koneoppimismallin opettamisessa ei ole käytössä luokittelijaa, joka ohjaisi mallia. Ohjaamattomuus ei kuitenkaan tarkoita sitä, että ohjaamattomassa koneoppimisessa ei olisi ollenkaan ohjaamista. Ohjaamista tapahtuu datan esikäsittelyvaiheessa, jossa mallintekijän pitää tehdä valintoja. Yksi tapa ohjata oppimista on kmeans-klusterien määrän valinta, johon liittyen myös koodiesimerkki on poimittu. \n",
    "\n",
    "Datan jaottelu tiettyihin koko luokkiin ennen klusterointia voi olla erittäin tarpeellista ja tarpeellisuus kasvaa, jos poikkeama-arvot ovat hyvin suuria. Ääripäiden rajaaminen ajaa samaa asiaa kuin tämä jakaminen, mutta silloin lopputloksena on vain yksi \"luokka\". Tietomassat noudattavast aina jotain jakaumaa ja, jos jakauma on liian vinoutunut, niin algoritmin tuottamat tulokset ovat epäluotettavia. \n",
    "\n",
    "Kävin jokin aika sitten Elements of AI -kurssin ja siellä koneoppiminen jaoteltiin kolmeen luokkaan\n",
    "- Ohjattu koneoppiminen\n",
    "- Ohjaamaton koneoppiminen\n",
    "- Vahvistus oppiminen\n",
    "Lisäksi kurssilla mainittiin, että usein ohjaamattoman ja ohjatun koneoppimisen raja on epäselvä, jolloin käytetään nimitystä puoliohjattu koneoppiminen (semisupervised learning). Puoliohjattua oppimista ja vahvistusoppimista ei käsitelty ollenkaan luentoviikoilla. \n",
    "\n",
    "Viimeisellä luentoviikon luennolla mainittiin, että oppimispäiväkirjoista 6 luentoviikon kohdalta tarkastellaan erityisesti hyviä lähteitä ohjaamattoman oppimisen kokonaiskuvan esittämisestä. Eli mitä kaikkia ohjaamattoman oppimisen tapoja on olemassa, sillä luennolla käytiin läpi vain muutama. Yritin etsiä tällaista koostekuvaa, mutta ainakaan yleisessä tietoisuudessa ei tunnu olevan muita kuin ryvästäminen ja aihemallinnus. Alla olevassa kuvassa on pari muutakin ja vertailtu eroja ohjaamattomaan oppimisen tapoihin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Differences-Between-Supervised-Learning-and-Unsupervised-Learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 oivallusta \n",
    "- Dataa joudutaan lähes aina muokkaamaan, jotta voidaan tehdä analyysi. Datan ääripisteet voivat tehdä malleista täysin epäloogisia, mutta samalla, kun ääripäitä rajataan, niin pitäisi kunnolla selvittää miksi sellaiset poikkeama-arot ovat syntyneet. Täysin ohjaamaton oppiminen on mahdotonta.\n",
    "- Ohjatussa oppimisessa on luokittelija, ohjaamattomassa ei ole luokittelijaa. Ennustettava piirre puuttuu\n",
    "- Ohjatussa oppimisessa ei pyritä ennustamaan \n",
    "- Datasta pyritään löytämään aikaisemmin tuntemattomia riippuvuuksia \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koodiesimerkki \n",
    "# Lähde: https://realpython.com/k-means-clustering-python/\n",
    "# Auttaa kertomaan, kuinka monta rypästä halutaan käyttää ryvästämisessä\n",
    "\n",
    "kmeans_kwargs = {\n",
    "    \"init\": \"random\",\n",
    "    \"n_init\": 10,\n",
    "    \"max_iter\": 300,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "# A list holds the SSE values for each k\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "   kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "   kmeans.fit(scaled_features)\n",
    "   sse.append(kmeans.inertia_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tärkeimmät kehityskohdat\n",
    "\n",
    "Luennolla mainittiin garbage in - garbage out haasteesta, mutta sen roolia ei ole mielestäni korostettu riittävästi. Työelämässä olen huomannut, että datan laatuongelmat ovat valtavat ja pahimmassa tapauksessa datan laatua joudutaan parantelemaan raportoinnissa. Mikä on oikea paikka korjata datan laatu? Se on prosesseissa ja datan alkulähteillä. Datatiede on kivaa pöhinää, mutta siitä ei saa tuloksia, jos data ei vastaa todellisuutta. \n",
    "\n",
    "Toinen datatieteeseen liittyvä haaste on tuotantoon vieminen, mutta se ei juurikaan ole kurssin sisällön näkökulmasta kovin keskeinen asia. Datatuotteen rakentaminen voisi kuitenkin olla viimeinen osa kurssia ja siinä voisi samalla käsitellä tuotantoon viemistä sekä sen haasteita. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luentoviikko 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visuaalinen analytiikka\n",
    "\n",
    "Ennakkotehtävänä datatuotteiden kehittämisestä kertova artikkeli. Luin artikkelin pintapuolisesti läpi ja mielestäni asian ytimessä, koska dataa tuotteistetaan ja palvelullistetaan jatkuvasti sekä uskon sen lisääntyvän. Olen miettinyt kohtuullisen paljon, että pystyisinkö itse jotenkin tuotteistamaan dataa tai ehkä lähinnä luomaan jollakin tavalla datan jalostamisella lisäarvoa potentiaalisille asiakkaille. Mielestäni datan tuotteistamisessa tärkeintä on, että se on sellaista, mikä kiinnostaa asiakasta. Esimerkiksi minua kiinnostaa omien rahojen käyttöön, sijoittamiseen ja terveyteen liittyvä tieto. Minua ei niinkään kiinnosta esimerkiksi sähkön tai energian käyttö asunnossa. Tällöin lähtökohdat datojen tuotteistamisessa ovat täysin erilaiset, koska tietyt asiat kiinnostaa asiakkaita enemmän kuin toiset. Kun löytää sellaisen tiedon, mikä kiinnostaa ihmisiä ja tietää mitää dataa tuottamalla/jalostamalla tähän tarpeesee voidaan vastata, pystyy rakentamaan erittäin hyvän datatuotteen. Pitää olla niin sanotusti business case, ennenkuin alkaa rakentamaan palvelua. Ei ole väliä, että miten hyvin jokin tuote/palvelu teknologisesti rakennetaan, jos se ei loppupeleissä kiinnosta kovin montaa tai tuota huimaa lisäarvoa. \n",
    "\n",
    "Katsoin luentoviikon tilaisuudet tallenteelta. Tämä viikko oli itselle antoisin aihe oppimisen kannalta, koska oli helppo omaksua uusia asioita aiemman osaamisen päälle. Visuaalisen analytiikan käsite on mielenkiintoinen ja mielestäni se eroaa huomattavasti visualisoinnista ja esittämisestä. Analytiikka tuo käsitteelle täysin eri merkityksen. Analytiikassa on kyse analyyttisestä päättelystä ohjelmoinnin/tietokoneen avulla ja visuaalisessa analytiikassa visualisoiminen on keskeinen osa päättelyä. \n",
    "\n",
    "Tietoa voidaan visualisoida kaikilla sen tasoilla ja tätä painotettiinkin paljon luennolla. Aihe on äärimmäisen vaikea ja osoitan tämän muutamalla esimerkillä. Kun jokin mittari tuottaa dataa, niin prosessin mittaus voi tapahtua millisekuntien välein, mutta mitattu data saattaa heitellä paljon, jolloin mittari automaattisesti saattaa prosesseida sitä tasaisemmaksi. Onko tällöin mittarin sekuntin välein tuottamat arvot dataa vai informaatiota, koska ne on laskettu millisekuntin tarkkuudella mitatuista arvoista? Tällainen sekuntin välein tuottettu mittaussarja, on kuitenkin erittäin massiivinen eikä ihminen pysty oikein ymmärtämään sarjaa, jos sitä saadaan vaikka parin tunnin edestä. Jos sekuntisarjasta lasketaan lasketaan tunnin keskiarvoja, summia ja mediaaneja, niin silloin tiedon määrä on huomattavasti pienentynyt ja jalostettu, mutta onko silloinkaan kyse vielä tietämyksestä. Jos näitä eri vaiheita esitettäisiin graafeilla, niin tarjoaisiko joku parhaimman näkymän. Jos mittausdataa lähdetään sitten vielä yhdistelemään asiakastietoihin ja voidaan tehdään vertailuja sekä klusterointia, niin syntyykö silloin tietämystä? Taso, jota visualisoidaan riippuu siitä mitä käyttäjä haluaa tietää. Se, että missä tiedon tasossa mennään, on aina tapauskohtaista, koska datat ovat erilaisia ja ne vastaavat eri kysymyksiin. Omasta mielestäni datan ja informaation raja menee tietomassan ymmärrettävässä laajuudessa. Data on sellaista, joka yksittäisenä lukuna tai arvona ei oikein tarkoita mitään. Informaatio kuitenkin kertoo jo jotakin. Vertaa esimerkiksi millisekuntin arvo ja minuutin keskiarvo. \n",
    "\n",
    "Tästä päästään myös luontevasti kysymyksen asettelun merkitykseen. Edellä mainittu käyttötapaus on periaattessa sama kuin kysymyksen asettelu. Käyttötarkoitus perustuu tietotarpeeseen ja tietotarpeeseen vastaaminen vaatii kysymykseen vastaamista. Ongelma on puettava kysymykseksi ja yleensä tämä kysymys on alkuun väärä. Se miksi kysymys on väärä, johtuu siitä, että ongelma on ymmärretty väärin ja kysytään väärää asiaa. Kun ongelmaa tutkitaan ja tietämys lisääntyy, niin osataankin kysyä oikeita asioita. Yleensä oikeisiin asioihin vastaaminen onkin sitten huomattavasti vaikeampaa. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 oivallusta \n",
    "- Jukallekaan ei ole selvää milloin mennään missäkin tiedon tasossa ja visualisoinnissa. Riippuu usein kontekstista ja useammalla mielipiteelle voi olla paikkansa. Viestinnän merkitys korostuu. \n",
    "- Visuaalisen analytiikan kaksi pääroolia ovat kartoittava eli eksploratiivinen rooli ja tulosten kommunikointi. Ensimmäistä näistä käyteään aina analytiikkaprojektissa kehitysvaiheessa. Jos eksploratiivinen raportti tai sovellus voi kuitenkin olla myös lopputuote. Tällöin loppukäyttäjä itse voi hakea tietoa ja tehdä niistä visualisointeja. \n",
    "- Tietämys ja varsinkaan viisaus eivät ole oikein sellaisia tiedon muotoja, joita voitaisiin analytiikan keinoin esittää. Tietämys ja viisaus syntyvät yleensä vasta ihmisen aivoissa. Toisaalta tekoäly voi muuttaa asioita. Joku saattaa kyseenalaistaa ajatuksen sillä, että koneoppimisella voidaan tuottaa sellaista tietoa jota ihminen ei ikinä itse keksisi. Mielestäni tällainen tieto ei ole merkityksellistä kuin vasta sitten, kun ihminen käyttää päätään mihin sitä voisi käyttää ja silloin syntyy tietämys. \n",
    "- pandas on hyvin laaja kirjasto ja se tarjoaa analytiikkaan oikeastaan kaiken mitä perus data-analytiikko tarvitsee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koodiesimerkki: \n",
    "\n",
    "# Scatterplot on mielestäni hyvä eksploratiivisen analytiikan vaihe, koska se tarjoaa useita datan visualisointeja kerralla\n",
    "# --> sen perusteella löytää mielenkiintoista tutkittavaa ja huomaa mihin ei välttämättä kannata panostaa\n",
    "data = ['O', 'P', 'M', 'S', 'L', 'R', 'Pelaaja_Ikä', 'Peliaika_minuutit']\n",
    "axis = pd.plotting.scatter_matrix(dataset[data], figsize=(12,12), c='red')\n",
    "\n",
    "# Tällaiset \"perusgraafit\" on paljon mielekkäämpää ja nopeampaa tehdä BI-työkalulla \n",
    "# Jos analytiikan tuloksena on datasetti, josta ei tarvitse esittää vaikeita visualisointeja, niin BI-työkalu parempi valinta\n",
    "dataset.groupby(['Kausi','Koko_nimi'])['Peliaika_minuutit'].sum().sort_values().plot(kind='barh', figsize=(10,18), title='KalPan pelaajien peliaikakeskiarvot vuosina 2018-2021')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Netistä esimerkki (animaatio) --> olisin halunnut osata tehdä harjoitustyöhön tällaisen animoidun graafin, mutta datasetti ei tarjonnut hyvää käyttötarkoitusta. \n",
    "# Animoitu graafi on ehkä hitaampi käyttää, mutta \"video\" havainnollistaa asioita paljon paremmin kuin kuva\n",
    "# Lähde: https://learn.sparkfun.com/tutorials/graph-sensor-data-with-python-and-matplotlib/update-a-graph-in-real-time\n",
    "\n",
    "\n",
    "# This function is called periodically from FuncAnimation\n",
    "def animate(i, xs, ys):\n",
    "\n",
    "    # Read temperature (Celsius) from TMP102\n",
    "    temp_c = round(tmp102.read_temp(), 2)\n",
    "\n",
    "    # Add x and y to lists\n",
    "    xs.append(dt.datetime.now().strftime('%H:%M:%S.%f'))\n",
    "    ys.append(temp_c)\n",
    "\n",
    "    # Limit x and y lists to 20 items\n",
    "    xs = xs[-20:]\n",
    "    ys = ys[-20:]\n",
    "\n",
    "    # Draw x and y lists\n",
    "    ax.clear()\n",
    "    ax.plot(xs, ys)\n",
    "\n",
    "    # Format plot\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.subplots_adjust(bottom=0.30)\n",
    "    plt.title('TMP102 Temperature over Time')\n",
    "    plt.ylabel('Temperature (deg C)')\n",
    "\n",
    "# Set up plot to call animate() function periodically\n",
    "ani = animation.FuncAnimation(fig, animate, fargs=(xs, ys), interval=1000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tärkeimmät kehityskohdat\n",
    "\n",
    "Miten kannattaa yhteensovittaa kaupallisia visualisointituotteita ja koodausta. Esimerkiksi Azuren tai Amazonin tietoaltaissa päälle voidaan rakentaa koneoppimismalleja ja jalostaa dataa moniin eri tarpeisiin. Tietoaltaaseen sitten kytketään visualisointi työkalu, jolla tuloksia esitellään. Tässä luentoviikossa aiheessa mennään toki napsua korkeammalla abstraktiotasolla, kun mietitään mikä on visuaalisen analytiikan rooli. Tulosten esittäminen työkalusta riippumatta on vain yksi rooli. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kiitos kurssista ja hyvää kesää"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
